{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "impossible-sacrifice",
   "metadata": {},
   "source": [
    "## Projeto Parte 1 - Pipeline de Treinamento\n",
    "Nome: Flávio Bezerra Pereira (flaviobp@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-parcel",
   "metadata": {},
   "source": [
    "### 1. Data extraction\n",
    "Loads a dataset with product data from a specified path available in the environment variable DATASET_PATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "architectural-receiver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPOSE_PROJECT_NAME=\"categorization\"\r",
      "\r\n",
      "\r",
      "\r\n",
      "DATASET_PATH=\"/usr/src/data/sample_products.csv\"\r",
      "\r\n",
      "METRICS_PATH=\"/usr/src/data/metrics.txt\"\r",
      "\r\n",
      "MODEL_PATH=\"/usr/src/data/model.pkl\"\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "\n",
    "# variaveis de ambiente\n",
    "!cat .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "black-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data-frame original\n",
    "DATASET_PATH=os.getenv(\"DATASET_PATH\")\n",
    "df_original = pd.read_csv(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-livestock",
   "metadata": {},
   "source": [
    "## 2. Data formatting\n",
    "Processes the dataset to use it for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defined-proposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do data frame: 37940\n",
      "Lembrancinhas         46.154454\n",
      "Decoração             22.965208\n",
      "Bebê                  18.236690\n",
      "Papel e Cia            7.208751\n",
      "Outros                 2.957301\n",
      "Bijuterias e Jóias     2.477596\n",
      "Name: category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# X -> concatenated_tags\n",
    "# y -> category\n",
    "\n",
    "# remove valores null e seleciona as colunas para X e y e verifica a distribuicao conforme a categoria\n",
    "df = df_original[['category','concatenated_tags','price','seller_id','weight']].dropna()\n",
    "print(\"Tamanho do data frame: \"+ str(len(df)))\n",
    "series = df['category'].value_counts()\n",
    "print(series/len(df)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "outstanding-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrai o target_names e y\n",
    "target_names = [category for category in df.category.unique()]\n",
    "y = [target_names.index(category)\n",
    "        for category in df.category]\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "parallel-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrai os valores para X\n",
    "feature_names = ['concatenated_tags']\n",
    "X = df[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "falling-professional",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho para treino: 34146\n",
      "Lembrancinhas         46.154747\n",
      "Decoração             22.966087\n",
      "Bebê                  18.236397\n",
      "Papel e Cia            7.207286\n",
      "Outros                 2.957887\n",
      "Bijuterias e Jóias     2.477596\n",
      "Name: category, dtype: float64\n",
      "Tamanho para teste: 3794\n",
      "Lembrancinhas         46.151819\n",
      "Decoração             22.957301\n",
      "Bebê                  18.239325\n",
      "Papel e Cia            7.221929\n",
      "Outros                 2.952030\n",
      "Bijuterias e Jóias     2.477596\n",
      "Name: category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide os dados para treino e teste de modo estratificado\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.1, #10% para teste train\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=420) #semente \n",
    "\n",
    "print(\"Tamanho para treino: \"+ str(len(y_train)))\n",
    "dy_train = pd.DataFrame([target_names[v] for v in y_train[0]], columns= ['category'])\n",
    "print(dy_train['category'].value_counts()/len(dy_train)*100)\n",
    "\n",
    "print(\"Tamanho para teste: \"+ str(len(y_test)))\n",
    "dy_test = pd.DataFrame([target_names[v] for v in y_test[0]], columns= ['category'])\n",
    "print(dy_test['category'].value_counts()/len(dy_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "addressed-archives",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34146, 56764)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# bag-of-words com bigrams\n",
    "count_vect = CountVectorizer(ngram_range=(1, 2),max_features=None,max_df=0.5)\n",
    "X_train_counts = count_vect.fit_transform(X_train['concatenated_tags'])\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "expensive-memorial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34146, 56764)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# tfidf ajuste na frequencia\n",
    "tfidf_transformer = TfidfTransformer(norm='l1',use_idf=True)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-powder",
   "metadata": {},
   "source": [
    "## 3. Modeling\n",
    "Specifies a model to handle the categorization problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "advanced-comfort",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média = 87.11708335414787  %.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import ComplementNB  \n",
    "from sklearn import metrics\n",
    "\n",
    "# abrir o arquivo de metricas\n",
    "METRICS_PATH=os.getenv(\"METRICS_PATH\")\n",
    "with open(METRICS_PATH, \"w\") as f:\n",
    "    print(\"MÉTRICAS NO CROSS-VALIDATION (n_splits=5)\", file=f)\n",
    "\n",
    "# cross validation com n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "acc_dt = []\n",
    "\n",
    "# pega um pedaco para treino outro para validacao em X e Y\n",
    "for tr_idx, vl_idx in skf.split(X_train_tfidf, y_train):\n",
    "    X_train_f, X_valid_f = X_train_tfidf[tr_idx], X_train_tfidf[vl_idx]\n",
    "    y_train_f, y_valid_f = y_train.iloc[tr_idx], y_train.iloc[vl_idx]\n",
    "    \n",
    "    clf = ComplementNB(alpha=0.01).fit(X_train_f, y_train_f.values.ravel())\n",
    "\n",
    "    y_pred_f = clf.predict(X_valid_f)\n",
    "    \n",
    "    acc_dt.append(accuracy_score(y_valid_f, y_pred_f))\n",
    "    \n",
    "    with open(METRICS_PATH, \"a\") as f:\n",
    "        print(metrics.classification_report(y_valid_f, y_pred_f,target_names=target_names), file=f)\n",
    "\n",
    "print(\"Acurácia média =\",np.mean(acc_dt)*100,\" %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-republican",
   "metadata": {},
   "source": [
    "## 4. Model validation\n",
    "Generates metrics about the model accuracy (precision, recall, F1, etc.) for each category and exports them to a specified path available in the environment variable METRICS_PATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "distant-technique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia = 88.03373748023195  %.\n"
     ]
    }
   ],
   "source": [
    "# treina o modelo com o conjunto de treino\n",
    "clfAll = ComplementNB(alpha=0.01).fit(X_train_tfidf, y_train.values.ravel())\n",
    "\n",
    "# calcula o erro do classificador nos dados de teste\n",
    "X_test_counts = count_vect.transform(X_test['concatenated_tags'])\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "y_pred = clfAll.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Acurácia =\",accuracy_score(y_test, y_pred)*100,\" %.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "painful-outreach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "         Decoração       0.88      0.88      0.88       871\n",
      "       Papel e Cia       0.83      0.66      0.74       274\n",
      "            Outros       0.86      0.71      0.77       112\n",
      "              Bebê       0.89      0.85      0.87       692\n",
      "     Lembrancinhas       0.88      0.94      0.91      1751\n",
      "Bijuterias e Jóias       0.89      0.95      0.92        94\n",
      "\n",
      "          accuracy                           0.88      3794\n",
      "         macro avg       0.87      0.83      0.85      3794\n",
      "      weighted avg       0.88      0.88      0.88      3794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# metricas\n",
    "print(metrics.classification_report(y_test, y_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "freelance-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporta para o arquivo as metricas\n",
    "METRICS_PATH=os.getenv(\"METRICS_PATH\")\n",
    "\n",
    "with open(METRICS_PATH, \"a\") as f:\n",
    "    print(\"MÉTRICAS NO TESTE\", file=f)\n",
    "    print(metrics.classification_report(y_test, y_pred,target_names=target_names), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "nearby-weather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MÉTRICAS NO CROSS-VALIDATION (n_splits=5)\r\n",
      "                    precision    recall  f1-score   support\r\n",
      "\r\n",
      "         Decoração       0.88      0.87      0.88      1569\r\n",
      "       Papel e Cia       0.79      0.70      0.74       492\r\n",
      "            Outros       0.70      0.69      0.70       202\r\n",
      "              Bebê       0.87      0.85      0.86      1245\r\n",
      "     Lembrancinhas       0.90      0.92      0.91      3152\r\n",
      "Bijuterias e Jóias       0.74      0.90      0.81       170\r\n",
      "\r\n",
      "          accuracy                           0.87      6830\r\n",
      "         macro avg       0.81      0.82      0.82      6830\r\n",
      "      weighted avg       0.87      0.87      0.87      6830\r\n",
      "\r\n",
      "                    precision    recall  f1-score   support\r\n",
      "\r\n",
      "         Decoração       0.88      0.87      0.88      1569\r\n",
      "       Papel e Cia       0.80      0.69      0.74       492\r\n",
      "            Outros       0.71      0.74      0.72       202\r\n",
      "              Bebê       0.88      0.86      0.87      1245\r\n",
      "     Lembrancinhas       0.90      0.92      0.91      3152\r\n",
      "Bijuterias e Jóias       0.70      0.93      0.80       169\r\n",
      "\r\n",
      "          accuracy                           0.88      6829\r\n",
      "         macro avg       0.81      0.84      0.82      6829\r\n",
      "      weighted avg       0.88      0.88      0.87      6829\r\n",
      "\r\n",
      "                    precision    recall  f1-score   support\r\n",
      "\r\n",
      "         Decoração       0.88      0.87      0.88      1568\r\n",
      "       Papel e Cia       0.78      0.71      0.74       493\r\n",
      "            Outros       0.63      0.69      0.66       202\r\n",
      "              Bebê       0.89      0.86      0.88      1245\r\n",
      "     Lembrancinhas       0.90      0.91      0.91      3152\r\n",
      "Bijuterias e Jóias       0.68      0.94      0.79       169\r\n",
      "\r\n",
      "          accuracy                           0.87      6829\r\n",
      "         macro avg       0.79      0.83      0.81      6829\r\n",
      "      weighted avg       0.87      0.87      0.87      6829\r\n",
      "\r\n",
      "                    precision    recall  f1-score   support\r\n",
      "\r\n",
      "         Decoração       0.89      0.87      0.88      1568\r\n",
      "       Papel e Cia       0.81      0.68      0.74       492\r\n",
      "            Outros       0.67      0.69      0.68       202\r\n",
      "              Bebê       0.87      0.86      0.86      1246\r\n",
      "     Lembrancinhas       0.89      0.91      0.90      3152\r\n",
      "Bijuterias e Jóias       0.68      0.90      0.77       169\r\n",
      "\r\n",
      "          accuracy                           0.87      6829\r\n",
      "         macro avg       0.80      0.82      0.81      6829\r\n",
      "      weighted avg       0.87      0.87      0.87      6829\r\n",
      "\r\n",
      "                    precision    recall  f1-score   support\r\n",
      "\r\n",
      "         Decoração       0.90      0.87      0.88      1568\r\n",
      "       Papel e Cia       0.80      0.68      0.73       492\r\n",
      "            Outros       0.74      0.67      0.70       202\r\n",
      "              Bebê       0.86      0.88      0.87      1246\r\n",
      "     Lembrancinhas       0.89      0.91      0.90      3152\r\n",
      "Bijuterias e Jóias       0.68      0.86      0.76       169\r\n",
      "\r\n",
      "          accuracy                           0.87      6829\r\n",
      "         macro avg       0.81      0.81      0.81      6829\r\n",
      "      weighted avg       0.87      0.87      0.87      6829\r\n",
      "\r\n",
      "MÉTRICAS NO TESTE\r\n",
      "                    precision    recall  f1-score   support\r\n",
      "\r\n",
      "         Decoração       0.88      0.88      0.88       871\r\n",
      "       Papel e Cia       0.83      0.66      0.74       274\r\n",
      "            Outros       0.86      0.71      0.77       112\r\n",
      "              Bebê       0.89      0.85      0.87       692\r\n",
      "     Lembrancinhas       0.88      0.94      0.91      1751\r\n",
      "Bijuterias e Jóias       0.89      0.95      0.92        94\r\n",
      "\r\n",
      "          accuracy                           0.88      3794\r\n",
      "         macro avg       0.87      0.83      0.85      3794\r\n",
      "      weighted avg       0.88      0.88      0.88      3794\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# visualiza o arquivo gerado\n",
    "!cat {METRICS_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-camping",
   "metadata": {},
   "source": [
    "## 5. Model exportation\n",
    "Exports a candidate model to a specified path available in the environment variable MODEL_PATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "usual-spelling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8803373748023194"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline para exportar o modelo selecionado\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1, 2),max_features=None,max_df=0.5)),\n",
    "    ('tfidf', TfidfTransformer(norm='l1',use_idf=True)),\n",
    "    ('clf', ComplementNB(alpha=0.01)),\n",
    "])\n",
    "\n",
    "# treina o modelo com todos os dados do conjunto de treino\n",
    "model.fit(X_train['concatenated_tags'], y_train.values.ravel())\n",
    "\n",
    "# predict com os dados de teste\n",
    "predicted = model.predict(X_test['concatenated_tags'])\n",
    "np.mean(predicted == y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "civic-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# gera o arquivo pkl\n",
    "MODEL_PATH=os.getenv(\"MODEL_PATH\")\n",
    "with open(MODEL_PATH, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "speaking-story",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 88.03 %\n"
     ]
    }
   ],
   "source": [
    "# testa o arquivo pkl\n",
    "with open(MODEL_PATH, 'rb') as file:\n",
    "    pickle_model = pickle.load(file)\n",
    "\n",
    "score = pickle_model.score(X_test['concatenated_tags'], y_test)\n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))\n",
    "Ypredict = pickle_model.predict(X_test['concatenated_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "timely-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OTIMIZACAO DE HIPERPARAMETROS\n",
    "### TRECHO COMENTADO POR CONTA DO TEMPO DE EXECUCAO \n",
    "\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#model = Pipeline([\n",
    "#    ('vect', CountVectorizer()),\n",
    "#    ('tfidf', TfidfTransformer()),\n",
    "#    ('clf', ComplementNB()),\n",
    "#])\n",
    "\n",
    "#parameters = {\n",
    "#    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "#    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "#    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "#    'tfidf__use_idf': (True, False),\n",
    "#    'tfidf__norm': ('l1', 'l2'),\n",
    "#    'clf__alpha': (0.01, 0.1, 0.5, 1.0, 10.0)\n",
    "#    #'clf__penalty': ('l2', 'elasticnet'),\n",
    "#    #'clf__n_iter': (10, 50, 80),\n",
    "#}\n",
    "\n",
    "#setting up the grid search\n",
    "#gs=GridSearchCV(model,parameters,n_jobs=-1,cv=5)\n",
    "\n",
    "##fitting gs to training data\n",
    "#gs.fit(X_train['concatenated_tags'], y_train.values.ravel())\n",
    "\n",
    "#print(gs.best_params_)\n",
    "##print(gs_clf.best_score_)\n",
    "#print(gs.best_score_)\n",
    "\n",
    "#print(\"Grid scores on development set:\")\n",
    "#print()\n",
    "#means = gs.cv_results_['mean_test_score']\n",
    "#stds = gs.cv_results_['std_test_score']\n",
    "#for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "#    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "#          % (mean, std * 2, params))\n",
    "#print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### RESULTADO DO AJUSTE DE HIPERPARAMETROS\n",
    "#{'clf__alpha': 0.01, 'tfidf__norm': 'l1', 'tfidf__use_idf': True, 'vect__max_df': 0.5, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
    "#0.8778290660120106"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
